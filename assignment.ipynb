{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverable 1\n",
    "### Research Question\n",
    "Based on performance metrics, are some football players overvalued?\n",
    "\n",
    "Hypothesis:\n",
    "- Players with higher goal-scoring rates have higher valuations, and those who are valuations far exceeding the indication given by the correlation are overvalued.\n",
    "\n",
    "Performance metrics available:\n",
    "- Goals scored per game\n",
    "- Assists per game\n",
    "- Minutes played\n",
    "- Matches starting eleven\n",
    "- Number of matches team captain\n",
    "- Clean sheets (for goalkeepers) (!!We can leave goalkeepers out, since their value evaluation metrics do not correspond to those of other player positions)\n",
    "- Age \n",
    "- Position (except goalkeeper since those have no goal and little to no assists)\n",
    "- Foot\n",
    "- Height\n",
    "\n",
    "Required datasets:\n",
    "- players.csv (to combine player-ids to actual names, birthcountry(?), age, position, foot, height, market value, highest market value)\n",
    "- game_lineups.csv (to get whether the player was starting and if he was team captain (maybe redundant))\n",
    "- appearances.csv (for each player appearance we get goals, assists, minutes_played)\n",
    "- clubs.csv (to combine club-id to actual club names) (needed?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverable 2\n",
    "\n",
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd, os, sys\n",
    "\n",
    "# Load datasets\n",
    "cwd = sys.path[0]\n",
    "players = pd.read_csv(cwd+'/archive/players.csv')\n",
    "lineups = pd.read_csv(cwd+'/archive/game_lineups.csv')\n",
    "appearances = pd.read_csv(cwd+'/archive/appearances.csv')\n",
    "clubs = pd.read_csv(cwd+'/archive/clubs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine \"lineups\" with \"appearances\", since those are match-based, and we will add the number-of-appearances-column to the \"players\" dataset.\n",
    "\n",
    "First we clean and preprocess the separate datasets by doing the following:\n",
    "\n",
    "- Look for contradictions in the datasets \"lineups\" and \"appearances\"\n",
    "\n",
    "- We join datasets on `game_id` and `player_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we inspect the dataframe\n",
    "\n",
    "print(appearances.isna().sum())\n",
    "print(lineups.isna().sum())\n",
    "\n",
    "print(lineups.shape, appearances.shape) #(2191911, 10) (1578761, 13)\n",
    "game_stats_na = lineups.merge(appearances, how='inner', on=['player_id', 'game_id'])\n",
    "print(game_stats_na.info())\n",
    "\n",
    "game_stats_na['player_name_y'] = game_stats_na['player_name_y'].fillna(game_stats_na['player_name_x'])\n",
    "game_stats = game_stats_na\n",
    "print(game_stats.info())\n",
    "\n",
    "# Since `date` and `player_name` should also be the same for both datasets we can look for contradictions now we have resolved all null values\n",
    "\n",
    "contradicting_dates_count = (game_stats['date_x'] != game_stats['date_y']).sum()\n",
    "\n",
    "print(f\"Number of rows with non-matching dates: {contradicting_dates_count}\")\n",
    "\n",
    "contradicting_names_count = (game_stats['player_name_x'] != game_stats['player_name_y']).sum()\n",
    "\n",
    "print(f\"Number of rows with non-matching names: {contradicting_names_count}\")\n",
    "\n",
    "\n",
    "# The data contains no contradictions for the dates, however it does contain 31986 contradictions for the names\n",
    "\n",
    "contradicting_names = game_stats[game_stats['player_name_x'] != game_stats['player_name_y']]\n",
    "print(f\"Unique contradicting names: {contradicting_names[['player_name_x', 'player_name_y']].nunique()}\")\n",
    "\n",
    "# We have 640 unique names that are contradicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve contradictions by character standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string\n",
    "players['first_name'] = players['first_name'].astype(str)\n",
    "players['last_name'] = players['last_name'].astype(str)\n",
    "players['name'] = players['name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_replacement = {\n",
    "    '-': ' ',\n",
    "    'ö': 'o',\n",
    "    'ó': 'o',\n",
    "    'ò': 'o',\n",
    "    'í': 'i',\n",
    "    'é': 'e',\n",
    "    'ä': 'a',\n",
    "    'ü': 'u',\n",
    "    'ß': 'ss',\n",
    "    'å': 'a',\n",
    "    'ø': 'o',\n",
    "    'ñ': 'n',\n",
    "    'ç': 'c',\n",
    "    'œ': 'oe',\n",
    "    'æ': 'ae',\n",
    "    'ė': 'e',\n",
    "    'ż': 'z',\n",
    "    'ł': 'l',\n",
    "    'č': 'c',\n",
    "    'ś': 's',\n",
    "    'ź': 'z',\n",
    "    'ñ': 'n',\n",
    "    'ã': 'a',\n",
    "    'į': 'i',\n",
    "    'š': 's',\n",
    "    'ž': 'z',\n",
    "    'đ': 'd',\n",
    "    'ć': 'c',\n",
    "    'ț': 't',\n",
    "    'ğ': 'g',\n",
    "    'ş': 's',\n",
    "    'î': 'i',\n",
    "    'ă': 'a',\n",
    "    'Ș': 'S',\n",
    "    'Ț': 'T',\n",
    "    'İ': 'I',\n",
    "    'ı': 'i',\n",
    "    'ё': 'e',\n",
    "    'й': 'i',\n",
    "    'ю': 'u',\n",
    "    'я': 'ya',\n",
    "    'ë': 'e',\n",
    "    'ș': 's',\n",
    "    'ţ': 't',\n",
    "    'ï': 'i',\n",
    "\n",
    "}\n",
    "\n",
    "def replace_special_chars(text, replacements):\n",
    "    for special_char, normal_char in replacements.items():\n",
    "        text = text.lower().replace(special_char, normal_char)\n",
    "    return text\n",
    "\n",
    "game_stats['player_name_x'] = game_stats['player_name_x'].apply(replace_special_chars, args=(char_replacement,))\n",
    "game_stats['player_name_y'] = game_stats['player_name_y'].apply(replace_special_chars, args=(char_replacement,))\n",
    "\n",
    "# Replace special characters in the first and last name columns of the players dataframe\n",
    "players['first_name'] = players['first_name'].apply(replace_special_chars, args=(char_replacement,))\n",
    "players['last_name'] = players['last_name'].apply(replace_special_chars, args=(char_replacement,))\n",
    "players['name'] = players['name'].apply(replace_special_chars, args=(char_replacement,))\n",
    "\n",
    "contradicting_names_count = (game_stats['player_name_x'] != game_stats['player_name_y']).sum()\n",
    "contradicting_names = game_stats[game_stats['player_name_x'] != game_stats['player_name_y']]\n",
    "print(f\"Number of rows with non-matching names: {contradicting_names_count}\")\n",
    "print(contradicting_names[['player_name_x', 'player_name_y']].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning capitals and special characters we still have 166 contradictions left. After inspection we can conclude these contradictions are regarding the inclusion of middle names, no first name or no second name.\n",
    "\n",
    "Since these do not directly affect our results we have chosen to make player_name_x the leading column since it is the most inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_stats_cleaned = game_stats.drop(['player_name_y', 'date_y'], axis=1).rename(columns={'player_name_x':'player_name', 'date_x':'date'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for conflicts such as duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = appearances.duplicated(subset=['player_id', 'game_id'], keep=False)\n",
    "duplicate_entries = appearances[duplicates]\n",
    "\n",
    "# We have 0 duplicate entries\n",
    "\n",
    "appearance_counts = game_stats_cleaned.groupby('player_id')['player_id'].count().reset_index(name='number_of_appearances')\n",
    "\n",
    "result_players = pd.merge(players, appearance_counts, on='player_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in the market value, we can remove all players for which we do not have an appearance count, because those players are not included in the metrics dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_players_clean = result_players.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert number of appearances to integer\n",
    "result_players_clean['number_of_appearances'] = result_players_clean['number_of_appearances'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "result_players_clean = result_players_clean.drop(['player_code', 'city_of_birth', 'country_of_citizenship', 'agent_name', 'image_url', 'url'], axis=1)\n",
    "game_stats_cleaned = game_stats_cleaned.drop(['number'], axis=1)\n",
    "\n",
    "# Change name of column name to player_name\n",
    "result_players_clean = result_players_clean.rename(columns={'name':'player_name', 'current_club_id':'player_current_club_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_stats_cleaned = game_stats_cleaned.merge(result_players_clean, on='player_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(cwd+'/clean', exist_ok=True)\n",
    "game_stats_cleaned.to_csv(cwd+'/clean/game_stats_cleaned.csv', index=False)\n",
    "result_players_clean.to_csv(cwd+'/clean/result_players_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverable 3\n",
    "As part of the poster, we need to attempt to deliver the answer to the research question. Therefore a knowledge graph is created here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24115/3664397204.py:4: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  game_stats_cleaned = pd.read_csv(cwd+\"/clean/game_stats_cleaned.csv\", index_col=0)\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "import sys, pandas as pd\n",
    "cwd = sys.path[0]\n",
    "game_stats_cleaned = pd.read_csv(cwd+\"/clean/game_stats_cleaned.csv\") # index_col=0\n",
    "result_players_clean = pd.read_csv(cwd+\"/clean/result_players_clean.csv\") # index_col=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N3cc847a20f294fda8e432376dfc91376 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef, Literal, BNode, Namespace, RDF\n",
    "\n",
    "n = Namespace(URIRef(\"http://example.org/\"))\n",
    "kg = Graph()\n",
    "kg.bind(\"ex\", n)\n",
    "\n",
    "# Append player_id to knowledge graphs\n",
    "for player_id in game_stats_cleaned.player_id.unique():\n",
    "    # Create subset df\n",
    "    player_df = game_stats_cleaned[game_stats_cleaned.player_id==player_id]\n",
    "    # Append player_id to knowledge graph\n",
    "    player_node = URIRef(n + str(player_id))\n",
    "    kg.add((player_node, RDF.type, n.player))\n",
    "    # Append player name to player_id\n",
    "    player_name = player_df.player_name.iloc[0]\n",
    "    kg.add((player_node, n.player_name, Literal(player_name)))\n",
    "    # Append games to player_id\n",
    "    for game_id in player_df.game_id:\n",
    "        game_node = BNode()\n",
    "        kg.add((game_node, RDF.type, n.game))\n",
    "        kg.add((player_node, n.played_in_game, game_node))\n",
    "        kg.add((game_node, n.id, Literal(game_id)))\n",
    "        # Append attributes to game_id\n",
    "        for attr, value in player_df[player_df.game_id==game_id].squeeze().items():\n",
    "            kg.add((game_node, n[attr], Literal(value)))\n",
    "    # Append attributes from result_players_clean to player_id\n",
    "    for attr, value in result_players_clean[result_players_clean.player_id==player_id].squeeze().items():\n",
    "        kg.add((player_node, n[attr], Literal(value if not isinstance(value,pd.Series) else None)))\n",
    "# Save\n",
    "kg.serialize(cwd+\"/knowledge_graph.ttl\", format=\"turtle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
